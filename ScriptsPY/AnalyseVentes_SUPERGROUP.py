#!/usr/bin/env python
# coding: utf-8

# ##1 - Import du drive contenant les factures

# In[8]:


from google.colab import drive
drive.mount('/content/drive', force_remount=True)


# In[ ]:


#packages √† installer
get_ipython().system('pip install pdfplumber')


# ###1.1 - Acc√®s au dossier contenant les factures

# In[ ]:


import os
import re
import pdfplumber
import pandas as pd


factures_supergroup = '/content/drive/My Drive/Analyse des Ventes/Factures SUPERGROUP'

# Liste tous les fichiers PDF dans le dossier
fichiers_pdf = [
    f for f in os.listdir(factures_supergroup)
    if f.lower().endswith('.pdf')
]

# Affiche les fichiers trouv√©s
print("üìÑ Factures trouv√©es :", fichiers_pdf)


# ##2 - Extraction des factures au format csv

# ###2.1 - Fonctions d'extraction des donn√©es pdf

# In[ ]:


# V√©rifie si une ligne correspond √† un article en commen√ßant par un code (6 √† 13 chiffres), avec √©ventuellement un ">" devant
def ligne_est_article(ligne):
    return bool(re.match(r'^(>?)(\d{6,13})\s+', ligne.strip()))

# Convertit une cha√Æne de caract√®res en float, en g√©rant les formats fran√ßais (virgule pour d√©cimal, point pour milliers)
def convertir_vers_float(valeur_str):
    if valeur_str is None:
        return 0.0
    return float(valeur_str.replace('.', '').replace(',', '.'))

# Extrait les donn√©es d'un article √† partir d'une ligne brute (code, d√©signation, quantit√©s, prix, etc.)
def extraire_article_depuis_ligne(ligne):
    ligne = ligne.strip()

    # Extrait le code article (6 √† 13 chiffres) au d√©but de la ligne
    match_code = re.match(r'^(>?)(\d{6,13})\s+', ligne)
    if not match_code:
        return None  # Pas un article reconnu

    code = match_code.group(2)
    reste = ligne[match_code.end():]  # Le reste de la ligne, sans le code

    # Les 5 derniers blocs sont toujours : quantit√©, conditionnement, prix, montant, TVA
    blocs = reste.split()
    if len(blocs) < 5:
        return None  # Implique que la ligne a pass√© le filtre parasites mais n'est aps un article

    try:
        tva = convertir_vers_float(blocs[-1])
        montant_ht = convertir_vers_float(blocs[-2])
        prix_u_ht = convertir_vers_float(blocs[-3])
        cond = int(blocs[-4])
        quantite = int(blocs[-5])
    except ValueError:
        return None  # Une des valeurs num√©riques est mal form√©e

    # Tout ce qui reste avant les 5 blocs num√©riques est la d√©signation de l‚Äôarticle
    designation = " ".join(blocs[:-5])

    return [code, designation, quantite, cond, prix_u_ht, montant_ht, tva]

# Extrait tous les articles d‚Äôun bloc de texte (souvent une page de facture)
def extraire_articles_depuis_bloc(bloc_texte):
    lignes = bloc_texte.strip().split('\n')[2:]  # Ignore les deux premi√®res lignes (souvent des en-t√™tes)
    articles = []
    articles_sans_famille = []

    # Lignes √† ignorer car ce ne sont pas des articles
    parasites = [
        r'^dont Taxe', r'^Points acquis', r'^Code Client', r'^Repr√©sentant',
        r'^TOTAL HT', r'^page \d+/\d+', r'^>?\d{6,13}\s+GMS\s+',
        r'^SUPERGROUP', r'^SOROWEN',
    ]

    # Familles de produits possibles
    familles_possibles = [
        "CONFISERIE", "BOISSONS", "EPICERIE", "PATISSERIE",
        "GUM", "PIPIER", "BISCUITERIE", "BISCUITERIE SALEE"
    ]

    famille_en_attente = None  # Pour m√©moriser la derni√®re famille d√©tect√©e

    for ligne in lignes:
        l = ligne.strip()

        # D√©tecte si une ligne correspond √† une famille de produits
        famille_detectee = None
        for famille in familles_possibles:
            if l.upper().startswith(famille):
                famille_detectee = famille.capitalize()
                break

        # Si une famille est d√©tect√©e, on l‚Äôapplique aux articles en attente
        if famille_detectee:
            famille_en_attente = famille_detectee
            for article in articles_sans_famille:
                article.append(famille_en_attente)
                articles.append(article)
            articles_sans_famille = []
            continue

        # Ignore les lignes parasites
        if any(re.match(p, l) for p in parasites):
            continue

        # Si la ligne est bien un article, on l'extrait
        if ligne_est_article(l):
            article = extraire_article_depuis_ligne(l)
            if article:
                articles_sans_famille.append(article)

    # √Ä la fin, on assigne "Inconnue" aux articles sans famille
    for article in articles_sans_famille:
        article.append('Inconnue')
        articles.append(article)

    return articles

# Traite un PDF de facture en extrayant tous les articles pr√©sents, avec leur fournisseur et date
def traiter_facture_individuelle(chemin_pdf):
    all_articles = []

    with pdfplumber.open(chemin_pdf) as pdf:
        for page in pdf.pages:
            texte = page.extract_text()
            if texte:
                articles = extraire_articles_depuis_bloc(texte)

                nom_fichier = os.path.basename(chemin_pdf)

                # Le nom du fournisseur est la partie avant "_Facture"
                fournisseur = nom_fichier.split('_Facture')[0]

                # On extrait la date au format AAAAMMJJ si elle est pr√©sente dans le nom du fichier
                match_date = re.search(r'_(\d{8})_', nom_fichier)
                if match_date:
                    date_facture = pd.to_datetime(match_date.group(1), format='%Y%m%d').date()
                else:
                    date_facture = None

                # On ajoute fournisseur et date √† chaque ligne d'article
                for article in articles:
                    article.append(fournisseur)
                    article.append(date_facture)

                all_articles.extend(articles)

    # Si on a trouv√© des articles, on les met dans un DataFrame
    if all_articles:
        df = pd.DataFrame(all_articles, columns=[
            "code", "designation", "quantite", "conditionnement",
            "prix_unitaire_ht", "montant_ht", "tva", "famille",
            "fournisseur", "date_facture"
        ])
        return df
    else:
        return pd.DataFrame()






# ###2.2 - Stockage des factures dans df_total

# In[ ]:


# Chaque facture = 1 df puis concat√©nation
dfs = []

for nom_fichier in fichiers_pdf:
    chemin_pdf = os.path.join(factures_supergroup, nom_fichier)
    print(f"Traitement de : {nom_fichier}")
    df_temp_supergroup = traiter_facture_individuelle(chemin_pdf)
    dfs.append(df_temp_supergroup)

df_total = pd.concat(dfs, ignore_index=True)
df_total.to_csv(os.path.join(factures_supergroup, 'articles_supergroup.csv'), index=False)


# ###2.3 - Pr√©-visualisation de df_total

# In[ ]:


chemin_csv = os.path.join(factures_supergroup, 'articles_supergroup.csv')
df_verification = pd.read_csv(chemin_csv)

# Affichage complet
display(df_verification)


# In[ ]:


# Nb refs ?
print(f"Nb r√©f: {len(df_verification)}\n")

# Formats ?
print(f"Types: {df_verification.dtypes}")


# ##3 - Formattage des donn√©es

# ###3.1 - Formattage des dates (str -> datetime)

# In[ ]:


# Format des dates
df_total['date_facture'] = pd.to_datetime(df_total['date_facture'], errors='coerce')  # Reconversion
df_total['date_facture'] = df_total['date_facture'].dt.strftime('%d/%m/%Y')  # Format JJ/MM/AAAA


# In[ ]:


# Affichage des 5 premi√®res lignes
display(df_total.head())


# In[ ]:


# R√©partition des articles par famille
repartition_refs = df_total['famille'].value_counts()
display(repartition_refs)

# Nombre d'articles mal class√©s (famille = 'Inconnue')
nb_inconnus = (df_total['famille'] == 'Inconnue').sum()

# Taux d'erreur = part des articles dont la famille n'a pas √©t√© d√©tect√©e
taux_erreur = nb_inconnus / len(df_total)

print(f"Taux d'erreur de classification : {taux_erreur:.2%}\n")



# ###3.2 - Formattage des quantit√©s et regroupement des lignes non uniques

# In[ ]:


def attribuer_famille_connue(group):
    familles_connues = group[group['famille'] != 'Inconnue']['famille']
    if not familles_connues.empty:
        famille_majoritaire = familles_connues.mode().iloc[0]
        group['famille'] = famille_majoritaire
    return group

df_total['famille'] = df_total['famille'].fillna('Inconnue')  # s√©curit√©
df_total = df_total.groupby('code', group_keys=False).apply(attribuer_famille_connue).reset_index(drop=True)


# In[ ]:


# R√©partition des articles par famille
repartition_refs = df_total['famille'].value_counts()
display(repartition_refs)

# Nombre d'articles mal class√©s (famille = 'Inconnue')
nb_inconnus = (df_total['famille'] == 'Inconnue').sum()

# Taux d'erreur = part des articles dont la famille n'a pas √©t√© d√©tect√©e
taux_erreur = nb_inconnus / len(df_total)

print(f"Taux d'erreur de classification : {taux_erreur:.2%}\n")


# In[ ]:


# √âtape 1 : Quantit√© totale par ligne
df_total["quantite_totale_ligne"] = df_total["quantite"] * df_total["conditionnement"]

# √âtape 2 : Tri pour identifier la derni√®re commande par article
df_total_sorted = df_total.sort_values("date_facture") # Ordre croissant

# √âtape 3 : Derni√®re commande
df_last_command = (
    df_total_sorted.groupby("code").last().reset_index()
    [["code", "quantite", "conditionnement"]]
    .rename(columns={"quantite": "dernier_quantite", "conditionnement": "dernier_conditionnement"})
)

# √âtape 4 : Synth√®se par article (maj des variables suivantes)
df_synthese = (
    df_total.groupby(["code", "designation", "fournisseur", "famille"])
    .agg(
        quantite_totale=("quantite_totale_ligne", "sum"),
        quantite_commande_totale=("quantite", "sum"),
        conditionnement_moyen=("conditionnement", "mean"),
        prix_unitaire_moyen=("prix_unitaire_ht", "mean"),
        nb_commandes=("quantite", "count"),
        dates_commande=("date_facture", lambda x: sorted(set(x))),
    )
    .reset_index()
)

# √âtape 5 : Fusion avec derni√®re commande en utilisant un left join
df_synthese = df_synthese.merge(df_last_command, on="code", how="left")

# √âtape 6 : Calcul des bornes
df_synthese["quantite_vendue_min"] = df_synthese["quantite_totale"] - (
    df_synthese["dernier_quantite"] * df_synthese["dernier_conditionnement"]
)
df_synthese["quantite_vendue_max"] = df_synthese["quantite_totale"]

# √âtape 7 : Format lisible de l'intervalle
df_synthese["quantite_vendue"] = df_synthese.apply(
    lambda row: f"{int(row.quantite_vendue_min)}"
    if row.quantite_vendue_min == row.quantite_vendue_max
    else f"{int(row.quantite_vendue_min)}-{int(row.quantite_vendue_max)}",
    axis=1
)

# R√©organisation finale
df_synthese = df_synthese[
    [
        "code", "designation", "fournisseur", "famille",
        "nb_commandes", "conditionnement_moyen",
        "quantite_totale", "quantite_vendue", "prix_unitaire_moyen",
        "nb_commandes", "dates_commande"
    ]
]


# In[ ]:


# Aper√ßu
print(df_synthese.head())


pd.set_option('display.max_rows', None)
display(df_synthese)
pd.reset_option('display.max_rows')


# ###3.3 - Calcul du CA avant lissage des ventes

# In[ ]:


# Nettoyer et extraire la borne min de quantite_vendue (format "min-max")
df_synthese["quantite_vendue_min"] = df_synthese["quantite_vendue"].str.extract(r"(\d+)", expand=False).astype(int)

# S'assurer que quantite_totale est bien num√©rique
df_synthese["quantite_totale"] = df_synthese["quantite_totale"].astype(float)

# Calculs
df_synthese["ca_potentiel"] = df_synthese["quantite_totale"] * df_synthese["prix_unitaire_moyen"]
df_synthese["ca_actuel"] = df_synthese["quantite_vendue_min"] * df_synthese["prix_unitaire_moyen"]
df_synthese["ca_potentiel_latent"] = df_synthese["ca_potentiel"] - df_synthese["ca_actuel"]




# In[ ]:


display(df_synthese)


# ###3.4 - Visualisation des donn√©es principales

# In[ ]:


import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# D√©finir les colonnes num√©riques pertinentes (ajuste si besoin)
colonnes_numeriques = [
    "conditionnement_moyen",
    "quantite_totale",
    "prix_unitaire_moyen",
    "ca_potentiel",
    "ca_actuel",
    "ca_potentiel_latent"
]

# Initialiser la figure
n = len(colonnes_numeriques)
fig, axes = plt.subplots(nrows=(n + 1) // 2, ncols=2, figsize=(18, n * 2.5))
axes = axes.flatten()  # Pour un acc√®s facile

# Tracer les histogrammes
for i, col in enumerate(colonnes_numeriques):
    if col in df_synthese.columns:
        # Convertir proprement en num√©rique, ignorer erreurs
        data = pd.to_numeric(df_synthese[col], errors='coerce')
        sns.histplot(data.dropna(), bins=50, kde=True, ax=axes[i], color="#69b3a2")
        axes[i].set_title(f"Distribution de {col}", fontsize=12)
    else:
        axes[i].text(0.5, 0.5, f"Colonne manquante : {col}", ha='center', va='center')
        axes[i].set_axis_off()

# Cacher les axes inutilis√©s si le nombre de graphes est impair
for j in range(i + 1, len(axes)):
    axes[j].set_axis_off()

plt.tight_layout()
plt.suptitle("Histogrammes des variables num√©riques de la synth√®se", fontsize=16, y=1.02)
plt.show()

# Les courbes repr√©sente la densit√© de population


# ###3.5 - Visualisation du CA et de la r√©partition des articles (avant lissage)

# In[ ]:


import matplotlib.pyplot as plt

# D√©finir la marge moyenne
marge_moyenne = 1.3

# Calcul du CA potentiel
df_synthese["ca_potentiel"] = df_synthese["quantite_totale"] * df_synthese["prix_unitaire_moyen"] * marge_moyenne

# Calcul du CA latent (diff√©rence entre le potentiel et le r√©el)
df_synthese["ca_latent"] = df_synthese["ca_potentiel"] - df_synthese["ca_actuel"]

# Agr√©gations par famille
nb_ref_par_famille = df_synthese.groupby("famille")["code"].nunique().sort_values(ascending=False)
volume_par_famille = df_synthese.groupby("famille")["quantite_totale"].sum().loc[nb_ref_par_famille.index]
ca_actuel_par_famille = df_synthese.groupby("famille")["ca_actuel"].sum().loc[nb_ref_par_famille.index]
ca_latent_par_famille = df_synthese.groupby("famille")["ca_latent"].sum().loc[nb_ref_par_famille.index]

# Cr√©ation des subplots
fig, axs = plt.subplots(1, 3, figsize=(22, 6))

# Graph 1 : Nb de r√©f√©rences
nb_ref_par_famille.plot(kind="bar", ax=axs[0], color="skyblue", edgecolor="black")
axs[0].set_title("Nb de r√©f√©rences par famille", fontsize=14)
axs[0].set_ylabel("R√©f√©rences")
axs[0].tick_params(axis='x', rotation=45)
axs[0].grid(axis="y", linestyle="--", alpha=0.7)

# Graph 2 : Volume total
volume_par_famille.plot(kind="bar", ax=axs[1], color="lightgreen", edgecolor="black")
axs[1].set_title("Volume total command√© par famille", fontsize=14)
axs[1].set_ylabel("Quantit√©")
axs[1].tick_params(axis='x', rotation=45)
axs[1].grid(axis="y", linestyle="--", alpha=0.7)

# Graph 3 : CA actuel et latent superpos√©s
axs[2].bar(ca_actuel_par_famille.index, ca_actuel_par_famille, label="CA Actuel", color="steelblue", edgecolor="black")
axs[2].bar(ca_latent_par_famille.index, ca_latent_par_famille, bottom=ca_actuel_par_famille, label="CA Latent", color="lightcoral", edgecolor="black")

axs[2].set_title("CA actuel vs potentiel par famille (avant lissage des ventes)", fontsize=14)
axs[2].set_ylabel("Montant (‚Ç¨)")
axs[2].tick_params(axis='x', rotation=45)
axs[2].grid(axis="y", linestyle="--", alpha=0.7)
axs[2].legend()

plt.tight_layout()
plt.show()


# In[ ]:


# V√©rification visuelle des valeurs
print(ca_latent_par_famille)
print(ca_actuel_par_famille)


# In[ ]:


import pandas as pd

# Assurer que 'date_facture' est bien en datetime
df_total['date_facture'] = pd.to_datetime(df_total['date_facture'], errors='coerce')

# Calcul des quantit√©s corrig√©es par le conditionnement
df_total['quantite_corrigee'] = df_total['quantite'] * df_total['conditionnement']

# Regroupement par r√©f√©rence
df_ref_info = df_total.groupby('code').agg(
    nb_commande=('code', 'size'),
    dates_commandes=('date_facture', lambda x: sorted(list(x))),
    quantites_commandees=('quantite_corrigee', lambda x: list(x)),
    prix_unitaire_moyen=('prix_unitaire_ht', 'mean'),
    famille=('famille', 'first')  # ou 'mode', ou 'unique' selon tes donn√©es
).reset_index()

#print(df_ref_info)



# ###3.6 - D√©finir l'intervalle de temps d'√©tude
# 

# In[ ]:


from datetime import datetime

# Extraire toutes les dates dans une seule liste (format datetime)
toutes_les_dates = [date for dates in df_ref_info['dates_commandes'] for date in dates]

# Premi√®re commande
premiere_commande_globale = min(toutes_les_dates)

# Derni√®re commande
derniere_commande_globale = max(toutes_les_dates)

# Affichage format√©
print(f"Premi√®re commande : {premiere_commande_globale.strftime('%d-%m-%Y')}")
print(f"Derni√®re commande : {derniere_commande_globale.strftime('%d-%m-%Y')}")


# ###3.7 - Cr√©ation de la df optimale d'√©tude

# On cherche √† cr√©e une df d'historique des ventes, pour cela on commence par cr√©er une df contenant les infos cl√©s de chaque r√©f√©rence unique.
# df_ref_info -> df_historique_ventes

# In[ ]:


import pandas as pd
from datetime import datetime, timedelta

# V√©rification du type et du nombre de valeurs NaT
print("Type de df_total['date_facture'] :", df_total['date_facture'].dtype)
print("Nombre de dates non converties (NaT) :", df_total['date_facture'].isna().sum())

# On filtre les lignes sans date
df_total_clean = df_total.dropna(subset=['date_facture']).copy()

# Cr√©ation d'une colonne pour le d√©but de semaine
df_total_clean['semaine_annee'] = df_total_clean['date_facture'].dt.to_period('W').apply(lambda r: r.start_time)

print("Type de df_total['date_facture'] :", df_total_clean['date_facture'].dtype)
print("Nombre de dates non converties (NaT) :", df_total_clean['date_facture'].isna().sum())

# Regroupement des donn√©es avec ajout de la d√©signation
df_ref_info = df_total_clean.groupby('code').agg(
    designation=('designation', 'first'),
    famille=('famille', 'first'),
    nb_commande=('code', 'size'),
    quantites_commandees=('quantite_corrigee', lambda x: list(x)),
    dates_commandes=('date_facture', lambda x: list(x)),
    prix_unitaire_moyen=('prix_unitaire_ht', 'mean')
).reset_index()

# Conversion des dates au format texte
df_ref_info['dates_commandes'] = df_ref_info['dates_commandes'].apply(
    lambda x: [date.strftime('%Y-%m-%d') for date in x]
)

# Dates extr√™mes
date_derniere_facture = df_ref_info['dates_commandes'].apply(max).max()
date_premiere_facture = df_ref_info['dates_commandes'].apply(min).min()

print("Date de la premi√®re facture :", date_premiere_facture)
print("Date de la derni√®re facture :", date_derniere_facture)
print(df_ref_info)


# ###3.8 - Lissage des ventes

# Afin de lisser les ventes nous proc√©dons de la fa√ßon suivante:
# 
# 1.   Si une r√©f√©rence est command√© √† deux dates diff√©rentes, cela implique que le stock entier a √©t√© vendu. On √©tale donc les ventes proportionnellement selon le nb de semaines entre les deux dates.
# 2.   Si une r√©f√©rence n'a √©t√© command√©e qu'une fois, on √©tale les ventes sur les 4 prochains mois (environ 17 semaines). *Il est rare de mettre plus de 4 mois √† √©couler un stock. Ces r√©f√©rences correspondent √† des offres limit√©s ou √† des produits arr√™t√©s.
# *D√©faut : chaque commande reset le stock ce qui est vrai en th√©orie

# In[ ]:


from datetime import datetime, timedelta
import pandas as pd

def etaler_ventes(ref, date_premiere_facture_globale):
    # Convertir les dates au bon format
    commandes = [pd.to_datetime(d) for d in ref['dates_commandes']]
    quantites = ref['quantites_commandees']

    # Lundi de la semaine actuelle
    today = datetime.today()
    lundi_courant = today - timedelta(days=today.weekday())

    # Liste de tous les lundis entre date_premiere_facture_globale et aujourd‚Äôhui
    all_mondays = pd.date_range(start=date_premiere_facture_globale, end=lundi_courant, freq='W-MON')

    ventes = [0] * len(all_mondays)  # Liste initialis√©e √† 0

    # Index de semaine pour la premi√®re commande de l'article
    for i in range(len(commandes)):
        date_debut = commandes[i]

        if i < len(commandes) - 1:
            date_fin = commandes[i + 1]
        else:
            # √âtaler sur 17 semaines apr√®s la derni√®re commande
            date_fin = date_debut + timedelta(weeks=17)

        semaines_a_remplir = pd.date_range(start=date_debut, end=date_fin, freq='W-MON')
        qte_par_semaine = quantites[i] / len(semaines_a_remplir) if len(semaines_a_remplir) > 0 else 0

        # Remplir les bonnes positions dans la liste `ventes`
        for semaine in semaines_a_remplir:
            if semaine >= date_premiere_facture_globale and semaine <= lundi_courant:
                idx = (semaine - date_premiere_facture_globale).days // 7
                if idx < len(ventes):
                    ventes[idx] += qte_par_semaine

    return ventes


# In[ ]:


# Date de d√©but globale
date_premiere_facture_globale = df_total['date_facture'].min()
date_aujourd_hui = datetime.today()
lundi_courant = date_aujourd_hui - timedelta(days=date_aujourd_hui.weekday())

# Liste des semaines (lundi de chaque semaine)
all_mondays = pd.date_range(start=date_premiere_facture_globale, end=lundi_courant, freq='W-MON')

# Construction de la liste de dictionnaires
historique_ventes = []

for _, row in df_ref_info.iterrows():
    code = row['code']
    designation = row['designation']
    famille = row['famille']
    prix = row['prix_unitaire_moyen']
    nb_commande = row['nb_commande']
    quantites_commandees = row['quantites_commandees']
    dates_commandes = row['dates_commandes']

    # Liste des quantit√©s hebdo √©tal√©es
    ventes_etalees = etaler_ventes(row, date_premiere_facture_globale)

    # Ajout d'une ligne par article, la colonne contient la liste des ventes
    historique_ventes.append({
        'code': code,
        'designation': designation,
        'famille': famille,
        'prix_unitaire_moyen': prix,
        'nb_commande': nb_commande,
        'quantites_commandees': quantites_commandees,
        'quantite_vendue': ventes_etalees,
        'dates_commandes': dates_commandes,
        'semaines': [d.strftime("%d/%m/%y") for d in all_mondays]
    })

# Cr√©ation du DataFrame final
df_historique_ventes = pd.DataFrame(historique_ventes)

# Affichage d‚Äôun exemple
print(df_historique_ventes.head())


# ###3.9 - Visualisation des ventes

# In[ ]:


import matplotlib.pyplot as plt

# R√©cup√©rer la liste des semaines (de 1√®re commande √† aujourd'hui)
semaines = df_historique_ventes.iloc[0]['semaines']

# Initialiser une liste √† 0 pour chaque semaine
total_ventes_par_semaine = [0] * len(semaines)

# Additionner les ventes semaine par semaine
for ventes in df_historique_ventes['quantite_vendue']:
    total_ventes_par_semaine = [sum(x) for x in zip(total_ventes_par_semaine, ventes)]

# Tracer le graphique
plt.figure(figsize=(14, 6))
plt.plot(semaines, total_ventes_par_semaine, marker='o')
plt.xticks(rotation=45)
plt.title("Total des ventes par semaine (toutes r√©f√©rences)")
plt.xlabel("Semaine")
plt.ylabel("Quantit√© vendue")
plt.tight_layout()
plt.grid(True)
plt.show()





# ###3.10 - Attribution du CA g√©n√©r√© par semaine par r√©f√©rence

# In[ ]:


# D√©finir la marge √† 30%
marge = 1.3

# Calculer le CA hebdomadaire pour chaque ligne
df_historique_ventes['ca_article'] = df_historique_ventes.apply(
    lambda row: [q * row['prix_unitaire_moyen'] * marge for q in row['quantite_vendue']],
    axis=1
)



# In[ ]:


# Recalcul du CA total (somme de tous les CA hebdomadaires)
ca_actuel = df_historique_ventes['ca_article'].apply(sum).sum()

print(f"Chiffre d'affaires actuel (avec marge {marge}): {ca_actuel:,.2f} ‚Ç¨")

#print(df_historique_ventes[df_historique_ventes['famille'] == 'Epicerie'])


# ###3.11 - Visualisation du CA

# ####3.11.1 - CA global par semaine

# In[ ]:


import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Exploser les colonnes pour avoir une ligne par semaine par article
df_exploded = df_historique_ventes.explode(['semaines', 'ca_article'])

# Conversion en datetime
df_exploded['semaines'] = pd.to_datetime(df_exploded['semaines'], format='%d/%m/%y')

# Grouper par semaine
df_ventes_global = df_exploded.groupby('semaines')['ca_article'].sum().reset_index()

# Graphique global
plt.figure(figsize=(12, 6))
sns.lineplot(data=df_ventes_global, x='semaines', y='ca_article', marker='o')
plt.title('Ventes globales par semaine (‚Ç¨)')
plt.ylabel('Chiffre d\'affaires (‚Ç¨)')
plt.xlabel('Semaine')
plt.grid(True)
plt.tight_layout()
plt.show()


# ####3.11.2 - CA par famille par semaine

# In[ ]:


# Grouper par semaine et famille
df_famille = df_exploded.groupby(['semaines', 'famille'])['ca_article'].sum().reset_index()

# Graphique par famille
plt.figure(figsize=(14, 7))
sns.lineplot(data=df_famille, x='semaines', y='ca_article', hue='famille', marker='o')
plt.title('Ventes par semaine et par famille (‚Ç¨)')
plt.ylabel('Chiffre d\'affaires (‚Ç¨)')
plt.xlabel('Mois')
plt.legend(title='Famille', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.show()


# In[ ]:


import pandas as pd
import plotly.express as px

df_famille = df_exploded.groupby(['semaines', 'famille'])['ca_article'].sum().reset_index()

# Assurer le format datetime pour manipulation
df_famille['semaines'] = pd.to_datetime(df_famille['semaines'])

# Graph plotly (interactif), 1 subplot par famille
fig = px.line(
    df_famille,
    x='semaines',
    y='ca_article',
    color='famille',
    facet_col='famille',
    facet_col_wrap=3,
    markers=True,
    title="Ventes hebdomadaires par famille (‚Ç¨)",
    labels={
        'semaines': 'Semaine',
        'ca_article': 'CA (‚Ç¨)',
        'famille': 'Famille'
    }
)

# Params d'affichage
fig.update_xaxes(tickangle=45)
fig.update_layout(
    height=600,
    showlegend=False,
    title_font_size=18,
    margin=dict(t=60, b=40, l=40, r=40)
)

fig.show()


# ##4 - Pr√©dictions

# ###4.1 - Pr√©diction du CA (toutes ann√©es)

# ####4.1.1 - Visualisation du CA cumul√©

# In[ ]:


# Grouper les donn√©es par semaine (global)
df_ventes_global = df_exploded.groupby('semaines')['ca_article'].sum().reset_index()
df_ventes_global['semaines'] = pd.to_datetime(df_ventes_global['semaines'])

# Ajouter le CA cumul√©
df_ventes_global['ca_cumule'] = df_ventes_global['ca_article'].cumsum()

# Tracer
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.plot(df_ventes_global['semaines'], df_ventes_global['ca_cumule'], marker='o', linestyle='-')
plt.title('CA cumul√© par semaine')
plt.xlabel('Semaine')
plt.ylabel('CA cumul√© (‚Ç¨)')
plt.grid(True)
plt.tight_layout()
plt.show()


# ###4.1 - Cr√©ation de la r√©gression

# In[ ]:


from sklearn.linear_model import LinearRegression
import numpy as np
import pandas as pd

# Variable num√©rique pour la semaine (X)
df_ventes_global = df_ventes_global.sort_values('semaines')
df_ventes_global['num_semaine'] = (df_ventes_global['semaines'] - df_ventes_global['semaines'].min()).dt.days // 7

# Pr√©parer les donn√©es pour la r√©gression
X = df_ventes_global[['num_semaine']]
y = df_ventes_global['ca_cumule']

# Entra√Æner le mod√®le
model = LinearRegression()
model.fit(X, y)

# Pr√©dire pour les semaines pass√©es + futures (par ex. 35 semaines en plus)
max_week = df_ventes_global['num_semaine'].max()
week_numbers = np.arange(0, max_week + 36)
X_full = pd.DataFrame({'num_semaine': week_numbers})

y_pred = model.predict(X_full)

# G√©n√©rer les dates associ√©es aux semaines
start_date = df_ventes_global['semaines'].min()
dates_full = start_date + pd.to_timedelta(X_full['num_semaine'] * 7, unit='D')


# In[ ]:


import plotly.graph_objects as go

# Tracer la courbe du CA (pointill√©s, ocre)
scatter = go.Scatter(
    x=df_ventes_global['semaines'],
    y=y,
    mode='markers',
    name='CA cumul√© r√©el',
    marker=dict(color='orange', size=6),
    hovertemplate='Date: %{x}<br>CA: %{y:.2f} ‚Ç¨'
)

# Tracer la droite de r√©gression (rouge, continue)
regression = go.Scatter(
    x=dates_full,
    y=y_pred,
    mode='lines',
    name='R√©gression lin√©aire',
    line=dict(color='red', width=2),
    hovertemplate='Date: %{x}<br>CA pr√©dit: %{y:.2f} ‚Ç¨'
)

# Figure compl√®te
fig = go.Figure(data=[scatter, regression])
fig.update_layout(
    title='R√©gression lin√©aire sur le CA cumul√© (SUPERGROUP)',
    xaxis_title='Date',
    yaxis_title='CA cumul√© (‚Ç¨)',
    hovermode='x unified',
    template='plotly_white',
    width=1000,
    height=500
)
fig.show()

# Affichage de l‚Äô√©quation
a = model.coef_[0]
b = model.intercept_
print(f"√âquation de la droite : CA_pr√©dit = {a:.2f} √ó semaine + ({b:.2f})")


# In[ ]:


display(df_ventes_global.head())


# In[ ]:


from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

# Calcul des m√©triques sur les donn√©es d'entra√Ænement
y_pred_train = model.predict(X)
r2 = r2_score(y, y_pred_train)
mae = mean_absolute_error(y, y_pred_train)
rmse = np.sqrt(mean_squared_error(y, y_pred_train))

# Affichage clair
print("√âvaluation du mod√®le de r√©gression lin√©aire :")
print(f"R¬≤    : {r2:.4f}")
print(f"MAE   : {mae:,.2f} ‚Ç¨")
print(f"RMSE  : {rmse:,.2f} ‚Ç¨")


# ###4.2 - Pr√©diction du CA(2025)

# ####4.2.1 - Pr√©diction du CA global

# In[ ]:


from sklearn.linear_model import LinearRegression
import numpy as np
import pandas as pd
import plotly.graph_objects as go

# Cr√©er la df d'entra√Ænement
df_train = df_ventes_global.copy()
df_train['num_semaine'] = (df_train['semaines'] - df_train['semaines'].min()).dt.days // 7
df_train['ca_cumule'] = df_train['ca_article'].cumsum()

# Entra√Ænement sur tout l‚Äôhistorique (pas que 2024)
X_train = df_train[['num_semaine']]
y_train = df_train['ca_cumule']

model = LinearRegression()
model.fit(X_train, y_train)

# Obtenir les semaines de 2025 (pr√©diction sur tout 2025)
start_2025 = pd.to_datetime('2025-01-01')
week_numbers_2025 = np.arange(0, 53)
week_offset = ((start_2025 - df_train['semaines'].min()).days) // 7
X_pred_2025 = pd.DataFrame({'num_semaine': week_numbers_2025 + week_offset})
y_pred_2025 = model.predict(X_pred_2025)

# Ajustement pour que le CA cumul√© en 2025 commence √† 0
y_pred_2025 = y_pred_2025 - y_pred_2025[0]
dates_pred_2025 = start_2025 + pd.to_timedelta(week_numbers_2025 * 7, unit='D')

# Extraire les donn√©es de 2025 pour les superposer √† la r√©gression
df_2025 = df_ventes_global[df_ventes_global['semaines'] >= '2025-01-01'].copy()
df_2025['ca_cumule'] = df_2025['ca_article'].cumsum()

# Tracer
scatter = go.Scatter(
    x=df_2025['semaines'],
    y=df_2025['ca_cumule'],
    mode='markers',
    name='CA cumul√© r√©el (2025)',
    marker=dict(color='orange', size=6),
    hovertemplate='Date: %{x}<br>CA: %{y:.2f} ‚Ç¨'
)

regression = go.Scatter(
    x=dates_pred_2025,
    y=y_pred_2025,
    mode='lines',
    name='R√©gression bas√©e sur l‚Äôhistorique',
    line=dict(color='red', width=2),
    hovertemplate='Date: %{x}<br>CA pr√©dit: %{y:.2f} ‚Ç¨'
)

fig = go.Figure(data=[scatter, regression])
fig.update_layout(
    title='Pr√©diction du CA cumul√© en 2025 (mod√®le entra√Æn√© toutes les ventes) - SUPERGROUP',
    xaxis_title='Date',
    yaxis_title='CA cumul√© (‚Ç¨)',
    hovermode='x unified',
    template='plotly_white',
    width=1000,
    height=500
)
fig.show()


# In[ ]:


# √âvaluation de la r√©gression

from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np

# Pr√©dire sur les donn√©es d'entra√Ænement
y_pred_train = model.predict(X_train)

# Calcul des m√©triques
r2 = r2_score(y_train, y_pred_train)
mae = mean_absolute_error(y_train, y_pred_train)
rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))

# Affichage
print(f"R¬≤ : {r2:.4f}")
print(f"Erreur Absolue Moyenne : {mae:.2f} ‚Ç¨")
print(f"√âcart-type Moyen des Erreurs : {rmse:.2f} ‚Ç¨")


# ####4.2.2 - Pr√©diction du CA par famille

# In[ ]:


display(df_historique_ventes)


# In[ ]:


display(df_synthese.head())


# In[ ]:


from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pandas as pd
import numpy as np
import plotly.graph_objects as go

# Cr√©ation du df des ventes d√©taill√©es
rows = []
for _, row in df_historique_ventes.iterrows():
    code = row['code']
    designation = row['designation']
    famille = row['famille']
    prix = row['prix_unitaire_moyen']
    nb_commande = row['nb_commande']
    quantites_commandees = row['quantites_commandees']
    dates_commandes = row['dates_commandes']
    semaines = pd.to_datetime(row['semaines'], format='%d/%m/%y')
    ca_values = row['ca_article']
    quantites_vendues = row['quantite_vendue']

    for date, ca in zip(semaines, ca_values):
        rows.append({
            'code': code,
            'designation': designation,
            'famille': famille,
            'prix_unitaire_moyen': prix,
            'nb_commande': nb_commande,
            'quantites_commandees': quantites_commandees,
            'dates_commandes': dates_commandes,
            'semaines': date,
            'quantite_vendue': quantites_vendues,
            'ca_article': ca
        })

df_ventes_detaillees = pd.DataFrame(rows)

# Supprimer les z√©ros initiaux par produit
df_ventes_detaillees = df_ventes_detaillees.sort_values(by=['code', 'semaines'])
df_ventes_detaillees = df_ventes_detaillees.groupby('code', group_keys=False).apply(
    lambda grp: grp.loc[grp['ca_article'].ne(0).idxmax():]
).reset_index(drop=True)

# Convertir dates et calculer num_semaine relatif
df_ventes_detaillees['semaines'] = pd.to_datetime(df_ventes_detaillees['semaines'])
df_ventes_detaillees['ca_article'] = df_ventes_detaillees['ca_article'].astype(float)

date_min = df_ventes_detaillees['semaines'].min()
df_ventes_detaillees['num_semaine'] = ((df_ventes_detaillees['semaines'] - date_min).dt.days // 7)

start_2025 = pd.to_datetime('2025-01-01')
num_semaine_2025 = np.arange(0, 53)  # 53 semaines en 2025

figs = []

for famille, group in df_ventes_detaillees.groupby('famille'):
    # Somme du CA par semaine
    df_ventes_famille = group.groupby('semaines')['ca_article'].sum().reset_index()
    df_ventes_famille = df_ventes_famille.sort_values('semaines')
    df_ventes_famille['num_semaine'] = ((df_ventes_famille['semaines'] - date_min).dt.days // 7)
    df_ventes_famille['ca_cumule'] = df_ventes_famille['ca_article'].cumsum()

    # Date de premi√®re commande r√©elle dans la famille (CA > 0)
    min_date = df_ventes_famille[df_ventes_famille['ca_article'] > 0]['semaines'].min()
    if pd.isna(min_date):
        print(f"Aucune commande r√©elle pour la famille {famille}, saut.")
        continue

    # Date de d√©but des pr√©dictions
    start_pred_date = max(start_2025, min_date)
    semaine_offset = ((start_pred_date - date_min).days) // 7

    # Pr√©paration r√©gression
    X = df_ventes_famille[['num_semaine']]
    y = df_ventes_famille['ca_cumule']
    model = LinearRegression()
    model.fit(X, y)

    # Pr√©dictions pour 2025
    X_pred = pd.DataFrame({'num_semaine': num_semaine_2025 + semaine_offset})
    y_pred = model.predict(X_pred)
    y_pred = y_pred - y_pred[0]  # Ajuster √† 0 √† la date de premi√®re commande

    # Donn√©es r√©elles 2025 (pour affichage)
    df_2025 = df_ventes_famille[df_ventes_famille['semaines'] >= start_2025].copy()
    df_2025['ca_cumule'] = df_2025['ca_article'].cumsum()

    # √âvaluation sur donn√©es connues
    y_pred_eval = model.predict(X)
    r2 = r2_score(y, y_pred_eval)
    mae = mean_absolute_error(y, y_pred_eval)
    rmse = np.sqrt(mean_squared_error(y, y_pred_eval))

    # Trace Plotly
    fig = go.Figure()

    fig.add_trace(go.Scatter(
        x=df_2025['semaines'],
        y=df_2025['ca_cumule'],
        mode='markers',
        name='CA r√©el',
        marker=dict(color='orange', size=6),
        hovertemplate='Date: %{x}<br>CA: %{y:.2f} ‚Ç¨'
    ))

    fig.add_trace(go.Scatter(
        x=start_pred_date + pd.to_timedelta(num_semaine_2025 * 7, unit='D'),
        y=y_pred,
        mode='lines',
        name='R√©gression',
        line=dict(color='red', width=2),
        hovertemplate='Date: %{x}<br>CA pr√©dit: %{y:.2f} ‚Ç¨'
    ))

    fig.update_layout(
        title=f"{famille} ‚Äì (R¬≤: {r2:.3f}, MAE: {mae:.2f} ‚Ç¨, RMSE: {rmse:.2f} ‚Ç¨)",
        xaxis_title="Date",
        yaxis_title="CA cumul√© (‚Ç¨)",
        hovermode='x unified',
        template='plotly_white',
        width=1000,
        height=400
    )

    figs.append(fig)

# Affichage des graphs
for fig in figs:
    fig.show()



# On remarque que les r√©gressions qui manquent de pr√©cision sont celles concernant les familles 'r√©centes' impliquant un manque de donn√©es.

# In[ ]:


#display(df_ventes_detaillees.head())


# ###5 - √âtude des meilleurs r√©f√©rences SUPERGROUP

# ####5.1 - Cr√©ation du df_top_references

# In[ ]:


# Cr√©er un DataFrame avec les meilleures r√©f/famille
top_references_by_famille = []

# Groupement par famille et tri des r√©f√©rences
for famille, group in df_ventes_detaillees.groupby('famille'):

    df_famille_group = group.groupby('code').agg({
        'ca_article': 'sum',
        'designation': 'first',
        'prix_unitaire_moyen': 'first',
        'nb_commande': 'first',
        'quantites_commandees': 'first',
        'quantite_vendue': 'first',
        'dates_commandes': 'first',
    }).reset_index()

    # Trier par CA d√©croissant et prendre les 10 meilleures r√©f√©rences
    top_references = df_famille_group.nlargest(10, 'ca_article')

    top_references['famille'] = famille
    top_references_by_famille.append(top_references)

# Fusionner les r√©s.
df_top_references = pd.concat(top_references_by_famille, ignore_index=True)

# Afficher les 10 meilleures r√©fs par famille
display(df_top_references)


# ####5.2 - Visualisation des meilleurs r√©fs par famille

# *Graphs interactifs, mais difficile √† lire dans l'√©tat due √† la quantit√© d'information. Possibilit√© de d√©selectionner les r√©f√©rences en cliquant sur la l√©gende associ√©e

# #####5.2.1 - Visualisation des ventes par refs par fam.

# In[ ]:


import pandas as pd
import plotly.graph_objects as go

# Copies pour √©viter de modifier les df d'origine
top_codes = df_top_references['code'].unique()
df_top_ventes = df_ventes_detaillees[df_ventes_detaillees['code'].isin(top_codes)].copy()

# Suppr. les semaines sans ventes :(avant 1√®re cmd) ajuste le poitn de d√©part du graph et √©vite de biaiser la donn√©es d'entra√Ænement pour la suite
df_top_ventes = df_top_ventes.sort_values(by=['code', 'semaines'])
df_top_ventes = df_top_ventes.groupby('code', group_keys=False).apply(
    lambda grp: grp.loc[grp['ca_article'].ne(0).idxmax():]
).reset_index(drop=True)

# Boucle sur les refs par famille
for famille, df_famille in df_top_ventes.groupby('famille'):
    fig = go.Figure()

    for code, df_produit in df_famille.groupby('code'):
        designation = df_produit['designation'].iloc[0]
        semaines = df_produit['semaines']
        ca_values = df_produit['ca_article']

        # Tracer la courbe des ventes
        fig.add_trace(go.Scatter(
            x=semaines,
            y=ca_values,
            mode='lines+markers',
            name=designation,
            marker=dict(symbol='circle', size=6),
            line=dict(width=2),
            hovertemplate='Semaine: %{x|%d/%m/%Y}<br>CA: %{y:.2f} ‚Ç¨'
        ))

    # Maj de la mise en page
    fig.update_layout(
        title=f"Ventes hebdomadaires ‚Äì {famille} (Top 10 produits)",
        xaxis_title="Semaine",
        yaxis_title="Chiffre d'affaires (‚Ç¨)",
        hovermode='x unified',
        template='plotly_white',
        width=1000,
        height=500
    )

    fig.show()


# #####5.2.2 - Visualisation des qt√© command√©es par refs par fam.

# In[ ]:


import pandas as pd
import plotly.graph_objects as go

#  f(x) qui normalise ttes les dates au lundi correspondant
def normalize_to_monday(d):
    return d - pd.Timedelta(days=d.weekday())

# Boucle sur chaque top_refs par famille
for famille, df_famille in df_top_references.groupby('famille'):
    fig = go.Figure()

    for _, row in df_famille.iterrows():
        code = row['code']
        designation = row['designation']
        dates_raw = pd.to_datetime(row['dates_commandes'])  # format dt?
        quantites_raw = row['quantites_commandees']

        # Normalisation des dates de cmd
        dates_norm = [normalize_to_monday(d) for d in dates_raw]

        # Association date : quantit√© command√©e
        quantites_par_date = {d: q for d, q in zip(dates_norm, quantites_raw)}

        # G√©n√©ration de toutes les semaines entre la 1√®re et la derni√®re cmd (=intervalle d'√©tude)
        toutes_semaines = pd.date_range(start=min(dates_norm), end=max(dates_norm), freq='W-MON')

        # Cr√©ation d'une liste de quantit√©s align√©e sur toutes les semaines (0 si pas de commande cette semaine)
        # Permet que toutes les listes fassent la mm taille pour la cr√©ation des graphs
        quantites_finales = [quantites_par_date.get(semaine, 0) for semaine in toutes_semaines]

        # Ajoute les trac√©s au mm graph
        fig.add_trace(go.Scatter(
            x=toutes_semaines,
            y=quantites_finales,
            mode='lines+markers',
            name=designation,
            marker=dict(symbol='circle', size=6),
            line=dict(width=2),
            hovertemplate='Semaine: %{x|%d/%m/%Y}<br>Quantit√©: %{y}'
        ))

    fig.update_layout(
        title=f"Quantit√©s command√©es ‚Äì {famille} (Top 10 produits)",
        xaxis_title="Semaine",
        yaxis_title="Quantit√©s command√©es",
        hovermode='x unified',
        template='plotly_white',
        width=1000,
        height=500
    )

    fig.show()



# ###5.3 - Pr√©diction des quantit√©s √† commander selon la fr√©quence de commande

# Le mod√®le cherche √† pr√©dire les quantit√©s sur les 4 semaines qui suivent la derni√®re commande en analysant la fr√©quence et les patterns de commande. Ce mod√®le est coh√©rent mais peut facilement √™tre biais√© s'il y a des probl√®mes de commande par exemple.

# In[ ]:


import pandas as pd
import numpy as np
from dateutil.relativedelta import relativedelta
import matplotlib.pyplot as plt
import seaborn as sns

# 1 - Pr√©paration des donn√©es
# Copie pour ne pas modifier l'original
df_top_references_pred = df_top_references.copy()

# Formats ?
df_top_references_pred['dates_commandes'] = df_top_references_pred['dates_commandes'].apply(
    lambda x: pd.to_datetime(x) if isinstance(x, list) else pd.to_datetime(eval(x)) #eval convertit des cha√Ænes contenant des lsites
)
df_top_references_pred['quantites_commandees'] = df_top_references_pred['quantites_commandees'].apply(
    lambda x: x if isinstance(x, list) else eval(x)
)

# R√©cup√©rer les conditionnements depuis df_synthese
df_conditionnements = df_synthese[['code', 'conditionnement_moyen']]
df_top_references_pred = df_top_references_pred.merge(df_conditionnements, on='code', how='left')

# Normalisation des dates et quantit√©s
def normalize_to_monday(d):
    return d - pd.Timedelta(days=d.weekday())

def normalize_quantities(dates_commandes, quantites, debut, fin):
    dates_norm = [normalize_to_monday(pd.to_datetime(d)) for d in dates_commandes]
    toutes_semaines = pd.date_range(start=debut, end=fin, freq='W-MON')
    mapping = dict(zip(dates_norm, quantites))
    return [mapping.get(semaine, 0) for semaine in toutes_semaines], toutes_semaines

donnees_produits = []

for _, row in df_top_references_pred.iterrows():
    code = row['code']
    dates = row['dates_commandes']
    quantites = row['quantites_commandees']
    cond = row['conditionnement_moyen']
    debut = normalize_to_monday(min(pd.to_datetime(dates)))
    fin = normalize_to_monday(pd.Timestamp.today())
    qte_norm, semaines = normalize_quantities(dates, quantites, debut, fin)
    donnees_produits.append({
        'code': code,
        'semaines': semaines,
        'quantites': qte_norm,
        'conditionnement_moyen': cond
    })

# 2 - Analyse & pr√©diction
resultats_pred = []

for produit in donnees_produits:
    code = produit['code']
    semaines = produit['semaines']
    quantites = produit['quantites']
    cond = produit['conditionnement_moyen']

    serie = pd.Series(quantites, index=semaines)

    # Calcul de la fr√©quence moyenne entre les commandes
    dates_commandes = serie[serie > 0].index
    if len(dates_commandes) < 2:
        continue  # pas assez de donn√©es

    deltas = dates_commandes.to_series().diff().dropna().dt.days
    frequence_moyenne = int(round(deltas.mean()))

    # Calcul d'une tendance lin√©aire
    x = np.arange(len(serie))
    y = np.array(serie)
    coeffs = np.polyfit(x, y, deg=1)
    tendance = np.poly1d(coeffs)

    # Pr√©diction pour les 4 prochaines semaines
    last_date = serie.index[-1]
    prochaines_semaines = [last_date + pd.Timedelta(weeks=i) for i in range(1, 5)]

    for i, semaine in enumerate(prochaines_semaines):
        jours_depuis_derniere_commande = (semaine - dates_commandes[-1]).days
        prob_commande = jours_depuis_derniere_commande >= frequence_moyenne

        if prob_commande:
            quantite_predite = max(0, int(round(tendance(len(serie) + i) / cond)) * cond)
        else:
            quantite_predite = 0

        resultats_pred.append({
            'code': code,
            'date_prevue': semaine,
            'quantite_predite': quantite_predite
        })

# R√©sultats
df_predictions = pd.DataFrame(resultats_pred)

df_predictions = df_predictions.merge(
    df_top_references_pred[['code', 'designation', 'famille']].drop_duplicates(),
    on='code', how='left'
)


# In[ ]:


import numpy as np
import pandas as pd
import plotly.express as px

# Fonction pour d√©tecter une p√©riodicit√© dans les derni√®res semaines d'une s√©rie
def detecter_periodicite_recente(series_quantites, max_lag=20, window=16):
    # On ne regarde que les x derni√®res semaines
    serie_recente = series_quantites[-window:]

    # Calcul des autocorr√©lations pour plusieurs d√©calages de semaines (=lag)
    autocorrs = [serie_recente.autocorr(lag=lag) for lag in range(1, max_lag+1)]

    # Si tous les r√©sultats sont NaN : impraticable
    if all(np.isnan(autocorrs)):
        return None

    # Retourne le lag avec la meilleure corr√©lation (indice + 1 car init. √† 0)
    period = np.nanargmax(autocorrs) + 1
    return period

def predire_par_repetition(dates_historique, quantites_historique, n_semaines_pred=8, conditionnement=1):
    """
    Pr√©dit les prochaines commandes en r√©p√©tant le sch√©ma des semaines pass√©es.
    La pr√©diction est arrondie au multiple du conditionnement.
    """

    # Sous-fonction pour aligner les dates sur les lundis
    def normalize_to_monday(d):
        return d - pd.Timedelta(days=d.weekday())

    # Normalise les dates de l'historique des ventes
    dates_norm = [normalize_to_monday(pd.to_datetime(d)) for d in dates_historique]
    debut = min(dates_norm)
    fin = normalize_to_monday(pd.Timestamp.today())

    # Cr√©e la liste compl√®te des semaines
    toutes_semaines = pd.date_range(start=debut, end=fin, freq='W-MON')
    mapping = dict(zip(dates_norm, quantites_historique))
    quantites_norm = [mapping.get(sem, 0) for sem in toutes_semaines]

    # S√©rie temporelle compl√®te (index = lundis, valeurs = quantit√©s)
    serie = pd.Series(quantites_norm, index=toutes_semaines)

    # D√©tecte la p√©riodicit√© de la s√©rie
    periode = detecter_periodicite_recente(serie)
    if periode is None:
        print("P√©riodicit√© non d√©tect√©e, utilisation d'une p√©riodicit√© de 1 semaine par d√©faut.")
        periode = 1
    else:
        print(f"P√©riodicit√© d√©tect√©e : {periode} semaines.")

    # G√©n√®re les prochaines semaines √† pr√©dire
    dernier_lundi = toutes_semaines[-1]
    dates_futures = [dernier_lundi + pd.Timedelta(weeks=i) for i in range(1, n_semaines_pred+1)]

    # R√©p√®te la derni√®re s√©quence connue selon la p√©riodicit√© d√©tect√©e
    seq_periodique = quantites_norm[-periode:]
    predictions_brutes = []
    for i in range(n_semaines_pred):
        val = seq_periodique[i % periode]
        # Arrondit √† un multiple du conditionnement
        val_arrondi = int(round(val / conditionnement) * conditionnement)
        predictions_brutes.append(max(0, val_arrondi))  # jamais de pr√©diction n√©gative

    # Format final des pr√©dictions
    df_pred = pd.DataFrame({
        'date_prevue': dates_futures,
        'quantite_predite': predictions_brutes
    })

    return serie, df_pred

# Affichage interactif pour un produit donn√©
def afficher_prediction_produit_interactif2(code_produit, df_top_references_pred, n_semaines_pred=8):
    produit = df_top_references_pred[df_top_references_pred['code'] == code_produit].iloc[0]

    dates_commandees = produit['dates_commandes']
    quantites_commandees = produit['quantites_commandees']
    conditionnement = produit['conditionnement_moyen']

    # Appelle la fonction de pr√©diction
    serie_hist, df_pred = predire_par_repetition(
        dates_commandees, quantites_commandees,
        n_semaines_pred, conditionnement
    )

    # Pr√©pare les donn√©es pour le graphe
    df_hist = serie_hist.reset_index()
    df_hist.columns = ['date', 'quantite']
    df_hist['type'] = 'Historique'
    df_pred['type'] = 'Pr√©diction'

    # Combine les historiques et les pr√©dictions dans un seul DataFrame
    df_combined = pd.concat([
        df_hist,
        df_pred.rename(columns={'date_prevue':'date', 'quantite_predite':'quantite'})
    ], ignore_index=True)

    # Affiche un graphique interactif
    fig = px.line(df_combined, x='date', y='quantite', color='type',
                  markers=True,
                  title=f"Quantit√©s command√©es et pr√©dites ‚Äì {produit['designation']} ({produit['famille']})",
                  labels={'quantite': 'Quantit√©', 'date': 'Date'})
    fig.update_layout(xaxis_title='Date (semaine)', yaxis_title='Quantit√© command√©e')
    fig.show()


# #####5.3.1 - Visualisation de la pr√©diction des commandeds (fr√©quence)

# In[ ]:


# Appelle la fonction pour un produit donn√©
afficher_prediction_produit_interactif2('8001118', df_top_references_pred, n_semaines_pred=8)


# In[ ]:


pd.set_option('display.max_rows', None)
display(df_top_references)
pd.reset_option('display.max_rows')


# ###5.4 - Pr√©diction de la quantit√© √† commander via la gestion du stock/les ventes

# Cette deuxi√®me m√©thode de pr√©diction sse base sur un nouveau √©talage des ventes qui inclut la simulation d'un stock. Cet √©talage se fait en fonction de la fr√©quence de commande (similaire au fonctionnement de la m√©thode 1). Pour cela, on initialise le stock de la semaine -1 √† 0 (semaine 0 = semaine de la 1√®re pr√©diction). Les scripts analysent les ventes hebdomadaires et d√©clenche des commandes quand on passe en dessous le seuil de 10% (par rapport au conditionnement).

# In[ ]:


# Une version plus stable et pr√©dictive, utilisable dans des mod√®les ou des tests reproductibles, l'√©talage se fait selon la fr√©quence
# au lieu d'un nb de semaine fixe, sauf si on manque de donn√©es
def etaler_ventes2(ref, date_debut_globale, nb_semaines):
    commandes = [pd.to_datetime(d) for d in ref['dates_commandes']]
    quantites = ref['quantites_commandees']

    ventes = [0] * nb_semaines

    # - de 2 cmd = √©talage sur 17sem.
    if len(commandes) < 2:
        date_debut = commandes[0]
        index_debut = (date_debut - date_debut_globale).days // 7
        for j in range(17):
            if 0 <= index_debut + j < nb_semaines:
                ventes[index_debut + j] += quantites[0] / 17
    # Sinon, √©talage selon la fr√©quence de moyenne de cmd
    else:
        for i in range(len(commandes)):
            date_debut = commandes[i]
            if i < len(commandes) - 1:
                date_fin = commandes[i + 1]
            else:
                deltas = [(commandes[j+1] - commandes[j]).days // 7 for j in range(len(commandes)-1)]
                freq_moy = int(np.mean(deltas)) if deltas else 17
                date_fin = date_debut + timedelta(weeks=freq_moy)

            semaines = pd.date_range(start=date_debut, end=date_fin, freq='W-MON')
            qte_par_semaine = quantites[i] / len(semaines) if len(semaines) > 0 else 0
            for semaine in semaines:
                idx = (semaine - date_debut_globale).days // 7
                if 0 <= idx < nb_semaines:
                    ventes[idx] += qte_par_semaine
    return ventes


# In[ ]:


# Pr√©dit le ca d'un article dont on a renseign√© le code
def predire_ca_article(df_ventes_detaillees, code, nb_semaines_a_predire):
    df_article = df_ventes_detaillees[df_ventes_detaillees['code'] == code].copy()
    if df_article.empty:
        raise ValueError("Code produit non trouv√©")

    df_article = df_article.sort_values('semaines')
    df_article['ca_cumule'] = df_article['ca_article'].cumsum()
    df_article['num_semaine'] = ((df_article['semaines'] - df_article['semaines'].min()).dt.days // 7)

    model = LinearRegression()
    model.fit(df_article[['num_semaine']], df_article['ca_cumule'])

    last_week = df_article['num_semaine'].max()
    semaines_futures = np.arange(last_week + 1, last_week + 1 + nb_semaines_a_predire)
    pred_cumule = model.predict(semaines_futures.reshape(-1, 1))
    pred_semaine = np.diff(np.concatenate([[df_article['ca_cumule'].iloc[-1]], pred_cumule]))

    return pred_semaine


# In[ ]:


def simuler_stock_et_commandes(qte_initiale, prix, marge, ca_prevu, conditionnement):
    stock = []
    commandes = []
    stock_actuel = qte_initiale

    for ca in ca_prevu:
        qte_sortie = np.ceil(ca / (prix * marge))  # quantit√©s vendues pr√©vues cette semaine

        # 1. V√©rifier le stock avant la sortie
        seuil = 0.1 * conditionnement
        if stock_actuel < seuil:
            manquant = max(0, -stock_actuel + seuil)
            n_cond = int(np.ceil(manquant / conditionnement))
            commande = n_cond * conditionnement
        else:
            commande = 0

        # 2. Mettre √† jour le stock avec la commande re√ßue
        stock_actuel += commande

        # 3. Retirer les ventes
        stock_actuel -= qte_sortie

        # 4. Enregistrer
        stock.append(stock_actuel)
        commandes.append(commande)

    return commandes, stock


def calculer_commandes(stock_simule, conditionnement):
    commandes = []
    for s in stock_simule:
        seuil = 0.1 * conditionnement
        if s < seuil:
            manquant = max(0, -s + seuil)
            n_cond = int(np.ceil(manquant / conditionnement))
            commandes.append(n_cond * conditionnement)
        else:
            commandes.append(0)
    return commandes



# In[ ]:


from sklearn.linear_model import LinearRegression
import numpy as np
import pandas as pd

def simuler_stock_et_commandes(stock_initial, prix_unitaire, marge, ca_prevu, conditionnement):
    """
    Simule le stock semaine par semaine √† partir d'un CA pr√©visionnel.
    Le stock est reconstitu√© via des commandes en multiples du conditionnement,
    d√©clench√©es si le stock ne permet pas de couvrir la demande.
    """
    stock = stock_initial
    commandes = []
    stock_semaine = []

    for ca in ca_prevu:
        # Calcule la demande pr√©vue en quantit√©s
        quantite_prevue = ca / (prix_unitaire * marge)

        # Si le stock ne suffit pas, on commande
        if stock < quantite_prevue:
            besoin = quantite_prevue - stock
            commande = int(np.ceil(besoin / conditionnement) * conditionnement)
            stock += commande
        else:
            commande = 0

        # Consomme le stock
        stock -= quantite_prevue
        stock = max(0, stock)  # s√©curit√© pour √©viter un stock n√©gatif

        # ‚úÖ Arrondi du stock √† l‚Äôunit√©
        stock_arrondi = int(round(stock))

        # Ajoute les r√©sultats de la semaine
        commandes.append(commande)
        stock_semaine.append(stock_arrondi)

        # Le stock pour la semaine suivante est la version arrondie
        stock = stock_arrondi

    return commandes, stock_semaine




# In[ ]:


import plotly.graph_objects as go
import pandas as pd

def afficher_commandes_et_stock(ca_prevu, commandes, stock, start_date=None):
    """
    Affiche un graphique interactif montrant les pr√©visions de CA, commandes √† passer et stock simul√©.

    """
    nb_semaines = len(ca_prevu)

    # Si aucune date de d√©part n'est fournie, on prend le lundi de cette semaine
    if start_date is None:
        today = pd.Timestamp.today()
        start_date = today - pd.Timedelta(days=today.weekday())

    dates = [start_date + pd.Timedelta(weeks=i) for i in range(nb_semaines)]

    # Pr√©paration des courbes
    fig = go.Figure()

    # Courbe 1 : CA pr√©visionnel (barres)
    fig.add_trace(go.Bar(
        x=dates, y=ca_prevu,
        name="CA pr√©visionnel",
        marker_color='lightblue',
        yaxis='y2',
        opacity=0.6
    ))

    # Courbe 2 : Commandes √† passer (barres)
    fig.add_trace(go.Bar(
        x=dates, y=commandes,
        name="Commandes √† passer",
        marker_color='orange',
        opacity=0.7
    ))

    # Courbe 3 : Stock simul√© (ligne)
    fig.add_trace(go.Scatter(
        x=dates, y=stock,
        mode='lines+markers',
        name="Stock simul√©",
        line=dict(color='green', width=3)
    ))

    fig.update_layout(
        title="Pr√©vision des commandes et du stock",
        xaxis_title="Date (semaine)",
        yaxis=dict(title="Commandes / Stock"),
        yaxis2=dict(title="CA", overlaying='y', side='right', showgrid=False),
        legend=dict(x=0.01, y=0.99),
        bargap=0.2,
        template="plotly_white"
    )

    fig.show()


# In[ ]:


display(df_synthese)


# In[ ]:


# Test
code = '8001118'
conditionnement = df_synthese[df_synthese['code'] == code]['conditionnement_moyen'].values[0]
prix = df_synthese[df_synthese['code'] == code]['prix_unitaire_moyen'].iloc[0]
marge = 1.3  # Marge moy. de 30%
stock_initial = 0
nb_semaines = 4

# Pr√©dire le chiffre d'affaires futur
ca_pred = predire_ca_article(df_ventes_detaillees, code, nb_semaines)

# Simuler le stock + commandes
commandes, stock = simuler_stock_et_commandes(stock_initial, prix, marge, ca_pred, conditionnement)


afficher_commandes_et_stock(ca_pred, commandes, stock)

print("Commandes √† passer sur 4 semaines :", commandes)
print("Stock simul√© :", stock)


# #Exportation Git

# In[1]:


get_ipython().system('apt-get install git -y')


# In[ ]:


get_ipython().system('git config --global user.name "owenvary"')
get_ipython().system('git config --global user.email "owen.vary@isen-ouest.yncrea.fr"')


# In[2]:


get_ipython().run_line_magic('cd', '/content')
get_ipython().system('git init')


# In[9]:


get_ipython().system('jupyter nbconvert --to python "/content/drive/MyDrive/Colab_Notebooks/AnalyseVentes_SUPERGROUP.ipynb"')


# In[10]:


get_ipython().system('cp "/content/drive/MyDrive/Colab_Notebooks/AnalyseVentes_SUPERGROUP.py" "/content/AnalyseVentes_SUPERGROUP.py"')


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:




